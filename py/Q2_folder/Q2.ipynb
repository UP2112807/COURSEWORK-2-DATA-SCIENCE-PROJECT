{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "85116527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3fa59981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>diet</th>\n",
       "      <th>life_stage</th>\n",
       "      <th>health_metrics</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>53.4</td>\n",
       "      <td>17.8</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5687.0</td>\n",
       "      <td>female</td>\n",
       "      <td>fish</td>\n",
       "      <td>adult</td>\n",
       "      <td>overweight</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>245.0</td>\n",
       "      <td>6811.0</td>\n",
       "      <td>female</td>\n",
       "      <td>fish</td>\n",
       "      <td>adult</td>\n",
       "      <td>overweight</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>55.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>226.0</td>\n",
       "      <td>5388.0</td>\n",
       "      <td>female</td>\n",
       "      <td>fish</td>\n",
       "      <td>adult</td>\n",
       "      <td>overweight</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>221.0</td>\n",
       "      <td>6262.0</td>\n",
       "      <td>female</td>\n",
       "      <td>fish</td>\n",
       "      <td>adult</td>\n",
       "      <td>overweight</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>60.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4811.0</td>\n",
       "      <td>female</td>\n",
       "      <td>fish</td>\n",
       "      <td>juvenile</td>\n",
       "      <td>overweight</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Biscoe            53.4           17.8              219.0   \n",
       "1  Adelie  Biscoe            49.3           18.1              245.0   \n",
       "2  Adelie  Biscoe            55.7           16.6              226.0   \n",
       "3  Adelie  Biscoe            38.0           15.6              221.0   \n",
       "4  Adelie  Biscoe            60.7           17.9              177.0   \n",
       "\n",
       "   body_mass_g     sex  diet life_stage health_metrics  year  \n",
       "0       5687.0  female  fish      adult     overweight  2021  \n",
       "1       6811.0  female  fish      adult     overweight  2021  \n",
       "2       5388.0  female  fish      adult     overweight  2021  \n",
       "3       6262.0  female  fish      adult     overweight  2021  \n",
       "4       4811.0  female  fish   juvenile     overweight  2021  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.kaggle.com/datasets/samybaladram/palmers-penguin-dataset-extended?select=palmerpenguins_extended.csv\n",
    "df_penguin = pd.read_csv(r'C:\\Users\\Billy\\Documents\\University\\Year 4\\Comp\\CW2\\palmerpenguins_extended.csv')\n",
    "df_penguin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fa007336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billy\\AppData\\Local\\Temp\\ipykernel_17000\\1265933689.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_penguin.island = df_penguin.island.replace({'Biscoe':0,'Dream':1,'Torgensen':2})\n",
      "C:\\Users\\Billy\\AppData\\Local\\Temp\\ipykernel_17000\\1265933689.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_penguin.species = df_penguin.species.replace({'Adelie':0,'Chinstrap':1,'Gentoo':2})\n",
      "C:\\Users\\Billy\\AppData\\Local\\Temp\\ipykernel_17000\\1265933689.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_penguin.sex = df_penguin.sex.replace({'female':0,'male':1})\n",
      "C:\\Users\\Billy\\AppData\\Local\\Temp\\ipykernel_17000\\1265933689.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_penguin.diet = df_penguin.diet.replace({'fish':0,'krill':1,'parental':2,'squid':3})\n",
      "C:\\Users\\Billy\\AppData\\Local\\Temp\\ipykernel_17000\\1265933689.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_penguin.life_stage = df_penguin.life_stage.replace({'adult':0,'juvenile':1,'chick':2})\n",
      "C:\\Users\\Billy\\AppData\\Local\\Temp\\ipykernel_17000\\1265933689.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_penguin.health_metrics = df_penguin.health_metrics.replace({'overweight':0,'healthy':1,'underweight':2})\n"
     ]
    }
   ],
   "source": [
    "df_penguin.drop('year',axis=1);\n",
    "df_penguin.island = df_penguin.island.replace({'Biscoe':0,'Dream':1,'Torgensen':2})\n",
    "df_penguin.species = df_penguin.species.replace({'Adelie':0,'Chinstrap':1,'Gentoo':2})\n",
    "df_penguin.sex = df_penguin.sex.replace({'female':0,'male':1})\n",
    "df_penguin.diet = df_penguin.diet.replace({'fish':0,'krill':1,'parental':2,'squid':3})\n",
    "df_penguin.life_stage = df_penguin.life_stage.replace({'adult':0,'juvenile':1,'chick':2})\n",
    "df_penguin.health_metrics = df_penguin.health_metrics.replace({'overweight':0,'healthy':1,'underweight':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d56df74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penguin = df_penguin.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a21adfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scale = scaler.fit_transform(df_penguin)\n",
    "df_penguin_scale = pd.DataFrame(df_scale,columns=df_penguin.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5fc09415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>diet</th>\n",
       "      <th>life_stage</th>\n",
       "      <th>health_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.4</td>\n",
       "      <td>17.8</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>245.0</td>\n",
       "      <td>6811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>226.0</td>\n",
       "      <td>5388.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>221.0</td>\n",
       "      <td>6262.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>6447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>25.2</td>\n",
       "      <td>245.0</td>\n",
       "      <td>6872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>258.0</td>\n",
       "      <td>7409.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>20.5</td>\n",
       "      <td>247.0</td>\n",
       "      <td>6491.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>206.0</td>\n",
       "      <td>6835.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3430 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0         0.0     0.0            53.4           17.8              219.0   \n",
       "1         0.0     0.0            49.3           18.1              245.0   \n",
       "2         0.0     0.0            55.7           16.6              226.0   \n",
       "3         0.0     0.0            38.0           15.6              221.0   \n",
       "4         0.0     0.0            60.7           17.9              177.0   \n",
       "...       ...     ...             ...            ...                ...   \n",
       "3425      2.0     0.0            44.0           20.4              252.0   \n",
       "3426      2.0     0.0            54.5           25.2              245.0   \n",
       "3427      2.0     0.0            51.4           20.4              258.0   \n",
       "3428      2.0     0.0            55.9           20.5              247.0   \n",
       "3429      2.0     0.0            43.9           22.9              206.0   \n",
       "\n",
       "      body_mass_g  sex  diet  life_stage  health_metrics  \n",
       "0          5687.0  0.0   0.0         0.0             0.0  \n",
       "1          6811.0  0.0   0.0         0.0             0.0  \n",
       "2          5388.0  0.0   0.0         0.0             0.0  \n",
       "3          6262.0  0.0   0.0         0.0             0.0  \n",
       "4          4811.0  0.0   0.0         1.0             0.0  \n",
       "...           ...  ...   ...         ...             ...  \n",
       "3425       6447.0  1.0   3.0         0.0             1.0  \n",
       "3426       6872.0  1.0   3.0         0.0             1.0  \n",
       "3427       7409.0  1.0   3.0         0.0             0.0  \n",
       "3428       6491.0  1.0   3.0         0.0             1.0  \n",
       "3429       6835.0  1.0   3.0         0.0             1.0  \n",
       "\n",
       "[3430 rows x 10 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_penguin.drop('year',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dde9a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_penguin_scale.drop('species',axis=1)\n",
    "y = pd.DataFrame(df_penguin_scale.species)\n",
    "X_tensor = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "67c09a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>diet</th>\n",
       "      <th>life_stage</th>\n",
       "      <th>health_metrics</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.009693</td>\n",
       "      <td>-0.862236</td>\n",
       "      <td>1.128816</td>\n",
       "      <td>-0.233287</td>\n",
       "      <td>0.413646</td>\n",
       "      <td>0.650156</td>\n",
       "      <td>-0.993606</td>\n",
       "      <td>-1.253284</td>\n",
       "      <td>-1.283947</td>\n",
       "      <td>-1.191135</td>\n",
       "      <td>-1.787749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.009693</td>\n",
       "      <td>-0.862236</td>\n",
       "      <td>0.817579</td>\n",
       "      <td>-0.125141</td>\n",
       "      <td>1.312039</td>\n",
       "      <td>1.507582</td>\n",
       "      <td>-0.993606</td>\n",
       "      <td>-1.253284</td>\n",
       "      <td>-1.283947</td>\n",
       "      <td>-1.191135</td>\n",
       "      <td>-1.787749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.009693</td>\n",
       "      <td>-0.862236</td>\n",
       "      <td>1.303412</td>\n",
       "      <td>-0.665871</td>\n",
       "      <td>0.655521</td>\n",
       "      <td>0.422068</td>\n",
       "      <td>-0.993606</td>\n",
       "      <td>-1.253284</td>\n",
       "      <td>-1.283947</td>\n",
       "      <td>-1.191135</td>\n",
       "      <td>-1.787749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.009693</td>\n",
       "      <td>-0.862236</td>\n",
       "      <td>-0.040220</td>\n",
       "      <td>-1.026358</td>\n",
       "      <td>0.482753</td>\n",
       "      <td>1.088786</td>\n",
       "      <td>-0.993606</td>\n",
       "      <td>-1.253284</td>\n",
       "      <td>-1.283947</td>\n",
       "      <td>-1.191135</td>\n",
       "      <td>-1.787749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.009693</td>\n",
       "      <td>-0.862236</td>\n",
       "      <td>1.682969</td>\n",
       "      <td>-0.197238</td>\n",
       "      <td>-1.037605</td>\n",
       "      <td>-0.018087</td>\n",
       "      <td>-0.993606</td>\n",
       "      <td>-1.253284</td>\n",
       "      <td>0.066540</td>\n",
       "      <td>-1.191135</td>\n",
       "      <td>-1.787749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    species    island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0 -1.009693 -0.862236        1.128816      -0.233287           0.413646   \n",
       "1 -1.009693 -0.862236        0.817579      -0.125141           1.312039   \n",
       "2 -1.009693 -0.862236        1.303412      -0.665871           0.655521   \n",
       "3 -1.009693 -0.862236       -0.040220      -1.026358           0.482753   \n",
       "4 -1.009693 -0.862236        1.682969      -0.197238          -1.037605   \n",
       "\n",
       "   body_mass_g       sex      diet  life_stage  health_metrics      year  \n",
       "0     0.650156 -0.993606 -1.253284   -1.283947       -1.191135 -1.787749  \n",
       "1     1.507582 -0.993606 -1.253284   -1.283947       -1.191135 -1.787749  \n",
       "2     0.422068 -0.993606 -1.253284   -1.283947       -1.191135 -1.787749  \n",
       "3     1.088786 -0.993606 -1.253284   -1.283947       -1.191135 -1.787749  \n",
       "4    -0.018087 -0.993606 -1.253284    0.066540       -1.191135 -1.787749  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfrom = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "df_penguin_scale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8cafc2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_tensor, y_tensor, test_size=0.25, random_state=23)\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor,y_tensor)\n",
    "data_size = len(dataset)\n",
    "\n",
    "trainSize = int(0.8*data_size)\n",
    "testSize = data_size - trainSize\n",
    "\n",
    "trainSet, testSet = torch.utils.data.random_split(dataset, [trainSize, testSize])\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainSet,batch_size=32)\n",
    "testLoader = torch.utils.data.DataLoader(testSet,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "91dd2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PenguinDataSet(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,pd_penguin):\n",
    "        self.species = df_penguin['species']\n",
    "        self.island = df_penguin['island']\n",
    "        self.bill_length_mm = df_penguin['bill_length_mm']\n",
    "        self.bill_depth_mm = df_penguin['bill_depth_mm']\n",
    "        self.flipper_length_mm = df_penguin['flipper_length_mm']\n",
    "        self.body_mass_g = df_penguin['body_mass_g']\n",
    "        self.sex = df_penguin['sex']\n",
    "        self.diet = df_penguin['diet']\n",
    "        self.life_stage = df_penguin['life_stage']\n",
    "        self.health_metrics = df_penguin['health_metrics']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.species)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        species = torch.tensor(self.species[index],dtype=torch.float64)\n",
    "        island = torch.tensor(self.island.iloc[index])\n",
    "        bill_length_mm = torch.tensor(self.bill_length_mm.iloc[index])\n",
    "        bill_depth_mm = torch.tensor(self.bill_depth_mm.iloc[index])\n",
    "        flipper_length_mm = torch.tensor(self.flipper_length_mm.iloc[index])\n",
    "        body_mass_g = torch.tensor(self.body_mass_g.iloc[index])\n",
    "        sex = torch.tensor(self.sex.iloc[index])\n",
    "        diet = torch.tensor(self.diet.iloc[index])\n",
    "        life_stage = torch.tensor(self.life_stage.iloc[index])\n",
    "        health_metrics = torch.tensor(self.health_metrics.iloc[index])\n",
    "\n",
    "        return species, island,\tbill_length_mm,\tbill_depth_mm, flipper_length_mm, body_mass_g, sex,\tdiet, life_stage, health_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6400566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PenguinData(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,features,classes):\n",
    "        #self.X = torch.tensor(features,dtype=torch.float64)\n",
    "        #self.y = torch.tensor(classes.values,dtype=torch.float32)\n",
    "\n",
    "        self.X = features\n",
    "        self.y = classes\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        classes = torch.tensor(self.y[index],dtype=torch.float64)\n",
    "        feature = torch.tensor(self.X[index].values,dtype=torch.float32)\n",
    "\n",
    "        return feature, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8ef4aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainSet = PenguinDataSet(df_penguin)\n",
    "#testSet = PenguinDataSet(df_penguin)\n",
    "#trainLoader = torch.utils.data.DataLoader(trainSet,batch_size=16)\n",
    "#testLoader = torch.utils.data.DataLoader(testSet,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c5d3f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainSet = PenguinData(Xtrain,ytrain)\n",
    "#testSet = PenguinData(Xtest,ytest)\n",
    "#trainLoader = torch.utils.data.DataLoader(trainSet,batch_size=16)\n",
    "#testLoader = torch.utils.data.DataLoader(testSet,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bff1d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9b7da2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(9,18,17)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \"\"\"Creates the second convolutional layer:\n",
    "            Input channels: 6 (output from conv1).\n",
    "            Output channels: 16.\n",
    "            Kernel size: 5x5.\"\"\"\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \"\"\"Defines the first fully connected (dense) layer:\n",
    "            Input size:  16x5x5, the flattened feature maps after the convolutional and pooling layers.\n",
    "            Output size: 120 (number of neurons in this layer).\"\"\"\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        \"\"\"Defines the second fully connected layer:\n",
    "            Input size: 120 (output from fc1).\n",
    "            Output size: 84.\"\"\"\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \"\"\"Defines the final fully connected layer:\n",
    "            Input size: 84 (output from fc2).\n",
    "            Output size: 10 (e.g., for a classification task with 10 classes).\"\"\"\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "     ##Defines the forward pass of the network. It specifies how the input ð‘¥ flows through the network.\n",
    "    def forward(self, x):\n",
    "        \"\"\"Passes x through the first convolutional layer (conv1), applies a ReLU activation, and then applies max pooling.\"\"\"\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \"\"\"Passes d through the second convolutional layer (conv2), applies a ReLU activation, and then applies max pooling\"\"\"\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \"\"\"Flattens the feature maps from 2D spatial dimensions into a single vector per feature map. The batch dimension is preserved.\"\"\"\n",
    "        x = torch.flatten(x, 1) \n",
    "        \"\"\"Passes the flattened tensor through the first fully connected layer (fc1) and applies a ReLU activation.\"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \"\"\"Passes x through the second fully connected layer (fc2) and applies a ReLU activation.\"\"\"\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \"\"\"Passes x through the final fully connected layer (fc3). No activation is applied here because this layer outputs raw scores (logits).\"\"\"\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() ##Defines the loss function that measures the error between the network's predictions and the true labels.\n",
    "\"\"\"Introduces momentum, which helps accelerate gradient descent and smoothens updates by incorporating information from previous updates\"\"\"\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) ##Defines the optimization algorithm to update the model's parameters during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8d7e246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0ce3f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NUM = 10\n",
    "HIDDEN_NUM = 18\n",
    "OUTPUT_NUM = len(df_penguin['species'].unique())\n",
    "\n",
    "class MultiClassNet(nn.Module):\n",
    "    def __init__(self, INPUT_NUM, HIDDEN_NUM, OUTPUT_NUM):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(INPUT_NUM, HIDDEN_NUM)\n",
    "        self.lin2 = nn.Linear(HIDDEN_NUM, OUTPUT_NUM)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.lin2(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        return x\n",
    "\n",
    "module = MultiClassNet(INPUT_NUM, HIDDEN_NUM, OUTPUT_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f71f3330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() ##Defines the loss function that measures the error between the network's predictions and the true labels.\n",
    "\"\"\"Introduces momentum, which helps accelerate gradient descent and smoothens updates by incorporating information from previous updates\"\"\"\n",
    "optimizer = optim.SGD(module.parameters(), lr=0.001, momentum=0.9) ##Defines the optimization algorithm to update the model's parameters during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "84af4a2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[197]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m y_hat_log = module(inputs)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat_log\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[32m     19\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Billy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Billy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Billy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1385\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m   1384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs the forward pass.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Billy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3458\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3457\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3459\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3465\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat_log = module(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(y_hat_log, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()  # Accumulate the loss for this epoch\n",
    "    \n",
    "    average_loss = epoch_loss / len(trainLoader)  # Calculate average loss for the epoch\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Print epoch number and loss\n",
    "    print(f\"Epoch {epoch + 1}/{num_epoch}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0c469041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydata(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        super().__init__()\n",
    "        self.X = torch.from_numpy(X_train.values).type(torch.FloatTensor)\n",
    "        self.y = torch.argmax(torch.from_numpy(y_train.values).type(torch.FloatTensor))\n",
    "        self.len = self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c2649f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penguin_scale = df_penguin_scale.drop('year',axis=1)\n",
    "X = df_penguin_scale.drop('species',axis=1)\n",
    "y = pd.DataFrame(df_penguin_scale.species)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0097],\n",
      "        [ 1.2125],\n",
      "        [-1.0097],\n",
      "        ...,\n",
      "        [-1.0097],\n",
      "        [ 1.2125],\n",
      "        [ 1.2125]])\n"
     ]
    }
   ],
   "source": [
    "target = torch.from_numpy(y_train.values).type(torch.FloatTensor)\n",
    "#target= torch.argmax(target ,axis=1)\n",
    "X_train.head()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d5c334d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Mydata(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=data_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d7d45e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NUM = 9\n",
    "HIDDEN_NUM = 20\n",
    "OUTPUT_NUM = 3\n",
    "\n",
    "class MultiClassNet(nn.Module):\n",
    "    def __init__(self, INPUT_NUM, HIDDEN_NUM, OUTPUT_NUM):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(INPUT_NUM, HIDDEN_NUM)\n",
    "        self.lin2 = nn.Linear(HIDDEN_NUM, OUTPUT_NUM)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "cda5e489",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[297]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[32m      9\u001b[39m     epoch_loss = \u001b[32m0.0\u001b[39m  \u001b[38;5;66;03m# Initialize loss for the current epoch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Initialize gradients\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Forward pass\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Billy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Billy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Billy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[295]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mMydata.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.argmax(\u001b[38;5;28mself\u001b[39m.X[index]), torch.argmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mIndexError\u001b[39m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "model = MultiClassNet(INPUT_NUM=INPUT_NUM, HIDDEN_NUM=HIDDEN_NUM, OUTPUT_NUM=OUTPUT_NUM)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "NUM_EPOCHS = 2\n",
    "losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0.0  # Initialize loss for the current epoch\n",
    "    for x, y in train_loader:\n",
    "      \n",
    "        # Initialize gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat_log = model(x)\n",
    "        \n",
    "        # Calculate loss\n",
    "        #print(\"y_hat\",y_hat_log)\n",
    "        print(\"y\",y)\n",
    "        loss = criterion(y_hat_log, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()  # Accumulate the loss for this epoch\n",
    "    \n",
    "    average_loss = epoch_loss / len(train_loader)  # Calculate average loss for the epoch\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Print epoch number and loss\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {average_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
